{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743878333.574946   21694 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743878333.579534   21694 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,roc_auc_score, classification_report, \n",
    "    confusion_matrix, ConfusionMatrixDisplay, roc_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, StackingClassifier, GradientBoostingClassifier, \n",
    "    HistGradientBoostingClassifier, AdaBoostClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier \n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from ngboost import NGBClassifier\n",
    "from ngboost.distns import Bernoulli \n",
    "from snapml import BoostingMachineClassifier  \n",
    "\n",
    "from lib.utils import gcForest\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load & Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi_category</th>\n",
       "      <th>map_category</th>\n",
       "      <th>age_category</th>\n",
       "      <th>gender</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bmi_category  map_category  age_category  gender  cholesterol  gluc  smoke  \\\n",
       "0             1             1             2       1            0     0      0   \n",
       "1             3             3             2       0            2     0      0   \n",
       "2             1             1             2       0            2     0      0   \n",
       "3             2             3             2       1            0     0      0   \n",
       "4             2             2             3       0            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('data/preprocessed_data_full_encoded_new_v3.csv')\n",
    "\n",
    "cols_to_keep = [\n",
    "                'bmi_category',\n",
    "                'map_category',\n",
    "                'age_category',\n",
    "                'gender',\n",
    "                'cholesterol', \n",
    "                'gluc',\n",
    "                'smoke', \n",
    "                'alco', \n",
    "                'active',\n",
    "                'cardio'\n",
    "                ]\n",
    "\n",
    "df = df[cols_to_keep]\n",
    "\n",
    "print('Sample Data') \n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('cardio', axis=1)  \n",
    "y = df['cardio']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {0: 'Healthy', 1: 'Cardio Risk'}\n",
    "target_names = [label_mapping[label] for label in y.unique()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scaling Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_cols = ['bmi_category', 'map_category', 'age_category', 'cholesterol', 'gluc']\n",
    "binary_cols = ['gender', 'smoke', 'alco', 'active']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), ordinal_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  \n",
    ")\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train, Val, Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "    X_preprocessed, y, test_size=0.2, random_state=42, stratify=y\n",
    ")  # Train 80%\n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_temp, y_temp, test_size=0.5, random_state=42\n",
    ")  # Val 10%, Test 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_np = np.array(x_train)\n",
    "y_train_np = np.array(y_train)\n",
    "x_test_np = np.array(x_test)\n",
    "y_test_np = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Base Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_train, y_train, x_test, y_test, model_name):\n",
    "    \n",
    "    if hasattr(model, 'cascade_forest'):\n",
    "        print(\"Using cascade_forest branch for training and prediction...\")\n",
    "        model.cascade_forest(x_train, y_train)\n",
    "        predict_func = lambda x: np.argmax(np.mean(model.cascade_forest(x), axis=0), axis=1)\n",
    "        predict_proba_func = lambda x: np.mean(model.cascade_forest(x), axis=0)\n",
    "    else:\n",
    "        print(\"Using standard branch (fit/predict/predict_proba)...\")\n",
    "        model.fit(x_train, y_train)\n",
    "        predict_func = lambda x: model.predict(x)\n",
    "        predict_proba_func = lambda x: model.predict_proba(x)\n",
    "\n",
    "    y_pred_test = predict_func(x_test)\n",
    "    y_proba_test = predict_proba_func(x_test)\n",
    "    \n",
    "    if y_proba_test.shape[1] > 1:\n",
    "        y_probs_test = y_proba_test[:, 1]\n",
    "    else:\n",
    "        y_probs_test = y_proba_test[:, 0]\n",
    "    \n",
    "    y_pred_train = predict_func(x_train)\n",
    "    y_proba_train = predict_proba_func(x_train)\n",
    "    if y_proba_train.shape[1] > 1:\n",
    "        y_probs_train = y_proba_train[:, 1]\n",
    "    else:\n",
    "        y_probs_train = y_proba_train[:, 0]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    test_acc_str = f\"{(test_accuracy * 100):.2f}%\"\n",
    "    test_auc = roc_auc_score(y_test, y_probs_test)\n",
    "    test_auc_str = f\"{test_auc:.4f}\"\n",
    "    test_report_dict = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "    test_precision = test_report_dict['weighted avg']['precision'] \n",
    "    test_recall    = test_report_dict['weighted avg']['recall']   \n",
    "    test_f1        = test_report_dict['weighted avg']['f1-score']\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    train_acc_str = f\"{(train_accuracy * 100):.2f}%\"\n",
    "    train_auc = roc_auc_score(y_train, y_probs_train)\n",
    "    train_auc_str = f\"{train_auc:.4f}\"\n",
    "    train_report_dict = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "    train_precision = train_report_dict['weighted avg']['precision']\n",
    "    train_recall    = train_report_dict['weighted avg']['recall']    \n",
    "    train_f1        = train_report_dict['weighted avg']['f1-score']  \n",
    "\n",
    "    data = [\n",
    "        [\"Test\", test_acc_str, test_auc_str],\n",
    "        [\"Train\", train_acc_str, train_auc_str]\n",
    "    ]\n",
    "\n",
    "    headers = [\"\", \"Accuracy\", \"AUC Score\"]\n",
    "\n",
    "    print(f\"\\n=== {model_name} ===\\n\")\n",
    "    print(tabulate(data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "    print(\"\\nOverfitting Check :\")\n",
    "    if train_accuracy > test_accuracy + 5 or train_auc > test_auc + 0.05:\n",
    "        print(\"The model might be overfitting.\")\n",
    "    else:\n",
    "        print(\"No significant signs of overfitting.\\n\")\n",
    "    \n",
    "    # # Plot Confusion Matrix and ROC Curve\n",
    "    # fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    # cm = confusion_matrix(y_test, y_pred_test)\n",
    "    # # If a global variable 'label_mapping' exists, use it for display labels\n",
    "    # display_labels = list(label_mapping.values()) if 'label_mapping' in globals() else None\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "    # disp.plot(ax=axes[0], cmap='viridis', colorbar=False)\n",
    "    # axes[0].set_title(f\"{model_name} - Confusion Matrix\")\n",
    "    \n",
    "    # fpr, tpr, _ = roc_curve(y_test, y_probs_test)\n",
    "    # axes[1].plot(fpr, tpr, label=f\"ROC Curve (AUC = {test_auc:.4f})\", linewidth=2)\n",
    "    # axes[1].plot([0, 1], [0, 1], 'k--', label=\"Random Guess\", linewidth=1)\n",
    "    # axes[1].set_title(f\"{model_name} - ROC Curve\")\n",
    "    # axes[1].legend(loc=\"lower right\")\n",
    "    # axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'train_precision': train_precision,\n",
    "        'train_recall': train_recall,\n",
    "        'train_f1': train_f1,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1\n",
    "    }\n",
    "\n",
    "\n",
    "def create_summary_table(results):\n",
    "    test_summary = pd.DataFrame([{\n",
    "        'Algorithm': r['model_name'],\n",
    "        'Accuracy':  round(r['test_accuracy'], 4),\n",
    "        'Precision': round(r['test_precision'], 4),\n",
    "        'Recall':    round(r['test_recall'], 4),\n",
    "        'F1-Score':  round(r['test_f1'], 4)\n",
    "    } for r in results])\n",
    "    train_summary = pd.DataFrame([{\n",
    "        'Algorithm': r['model_name'],\n",
    "        'Accuracy':  round(r['train_accuracy'], 4),\n",
    "        'Precision': round(r['train_precision'], 4),\n",
    "        'Recall':    round(r['train_recall'], 4),\n",
    "        'F1-Score':  round(r['train_f1'], 4)\n",
    "    } for r in results])\n",
    "    \n",
    "    \n",
    "    print(\"\\nSummary Table - Test Metrics\")\n",
    "    print(tabulate(test_summary, headers='keys', tablefmt='grid', showindex=False))\n",
    "\n",
    "    print(\"Summary Table - Training Metrics\")\n",
    "    print(tabulate(train_summary, headers='keys', tablefmt='grid', showindex=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Logistic Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== Logistic Regression ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 81.87%     |      0.8722 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 82.44%     |      0.8788 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression()\n",
    "logreg_results = evaluate_model(logreg_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Logistic Regression\")\n",
    "logreg_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Random Forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== Random Forest ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.43%     |      0.9401 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 87.54%     |      0.9567 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_results = evaluate_model(rf_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Random Forest\")\n",
    "rf_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Decision Tree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== Decision Tree ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.19%     |      0.9318 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 87.54%     |      0.9571 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_results = evaluate_model(dt_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Decision Tree\")\n",
    "dt_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `SVM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== SVM ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.71%     |      0.9167 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 86.06%     |      0.9205 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(probability=True)\n",
    "svm_results = evaluate_model(svm_model, x_train_np, y_train_np, x_test_np, y_test_np, \"SVM\")\n",
    "svm_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Naive Bayes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== Naive Bayes ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 77.46%     |      0.8478 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 77.96%     |      0.8546 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_results = evaluate_model(nb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Naive Bayes\")\n",
    "nb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `KNN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== KNN ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 82.90%     |      0.9195 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 85.12%     |      0.9337 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_results = evaluate_model(knn_model, x_train_np, y_train_np, x_test_np, y_test_np, \"KNN\")\n",
    "knn_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `XGBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== XGBoost ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.67%     |      0.942  |\n",
      "+-------+------------+-------------+\n",
      "| Train | 87.05%     |      0.9535 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_results = evaluate_model(xgb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"XGBoost\")\n",
    "xgb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Light GBM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== LightGBM ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.89%     |      0.9431 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 86.59%     |      0.9505 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm_model = LGBMClassifier(verbose=-1)\n",
    "lgbm_results = evaluate_model(lgbm_model, x_train_np, y_train_np, x_test_np, y_test_np, \"LightGBM\")\n",
    "lgbm_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Cat Boost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== CatBoost ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.75%     |      0.9417 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 87.11%     |      0.9538 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "catb_model = CatBoostClassifier(verbose=False)\n",
    "catb_results = evaluate_model(catb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"CatBoost\")\n",
    "catb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `SnapBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== SnapBoost ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.55%     |      0.9395 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 85.80%     |      0.9436 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snb_model = BoostingMachineClassifier()\n",
    "snb_results = evaluate_model(snb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"SnapBoost\")\n",
    "snb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Explainable Boosting Machine (EBM)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== EBM ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 84.93%     |      0.9324 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 85.00%     |      0.9357 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ebm_model = ExplainableBoostingClassifier(n_jobs=1)\n",
    "ebm_results = evaluate_model(ebm_model, x_train_np, y_train_np, x_test_np, y_test_np, \"EBM\")\n",
    "ebm_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `NGBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== NGBoost ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 84.08%     |      0.9281 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 84.53%     |      0.9319 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngb_model = NGBClassifier(Dist=Bernoulli, verbose=False)\n",
    "ngb_results = evaluate_model(ngb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"NGBoost\")\n",
    "ngb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `AdaBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== AdaBoost ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 84.12%     |      0.8998 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 84.17%     |      0.9082 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adb_model = AdaBoostClassifier(random_state=42)\n",
    "adb_results = evaluate_model(adb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"AdaBoost\")\n",
    "adb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `GradientBoosting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== Gradient Boosting ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.09%     |      0.9362 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 85.18%     |      0.9397 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grb_model =  GradientBoostingClassifier(random_state=42)\n",
    "grb_results = evaluate_model(grb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Gradient Boosting\")\n",
    "grb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Hist GradientBoosting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== Hist Gradient Boosting ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.67%     |      0.943  |\n",
      "+-------+------------+-------------+\n",
      "| Train | 86.61%     |      0.9502 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hgrb_model =  HistGradientBoostingClassifier(random_state=42)\n",
    "hgrb_results = evaluate_model(hgrb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Hist Gradient Boosting\")\n",
    "hgrb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Cascaded Random Forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cascade_forest branch for training and prediction...\n",
      "Adding/Training Layer, n_layer=1\n",
      "Layer validation accuracy = 0.8420524400953456\n",
      "Adding/Training Layer, n_layer=2\n",
      "Layer validation accuracy = 0.8471960858110651\n",
      "Adding/Training Layer, n_layer=3\n",
      "Layer validation accuracy = 0.8508342742441349\n",
      "Adding/Training Layer, n_layer=4\n",
      "Layer validation accuracy = 0.8510851837912432\n",
      "Adding/Training Layer, n_layer=5\n",
      "Layer validation accuracy = 0.8513360933383515\n",
      "Adding/Training Layer, n_layer=6\n",
      "Layer validation accuracy = 0.8528415506210011\n",
      "Adding/Training Layer, n_layer=7\n",
      "Layer validation accuracy = 0.8514615481119057\n",
      "\n",
      "=== Cascaded Random Forest ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.31%     |      0.9409 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 85.88%     |      0.9441 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gcf_model = gcForest(n_cascadeRF=2,n_cascadeRFtree=500) #Default values tolerance =0.0 ,n_cascadeRFtree=101\n",
    "gcf_results = evaluate_model(gcf_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Cascaded Random Forest\")\n",
    "gcf_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TabNet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== TabNet Classifier ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.67%     |      0.9434 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 86.30%     |      0.9472 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabnet_model = TabNetClassifier(verbose=0)\n",
    "tabnet_results = evaluate_model(tabnet_model, x_train_np, y_train_np, x_test_np, y_test_np, \"TabNet Classifier\")\n",
    "tabnet_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `NN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasModelWrapper(BaseEstimator):\n",
    "    def __init__(self, model, epochs=100, batch_size=32, validation_split=0.2, callbacks=None):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_split = validation_split\n",
    "        self.callbacks = callbacks\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.model.fit(\n",
    "            x, y,\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            validation_split=self.validation_split,\n",
    "            callbacks=self.callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        proba = self.model.predict(x)\n",
    "        return (proba > 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        proba = self.model.predict(x)\n",
    "        return np.hstack([1 - proba, proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m1246/1246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 972us/step\n",
      "\n",
      "=== Keras Sequential Model ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.85%     |      0.9437 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 86.39%     |      0.9478 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, input_dim=x_train_np.shape[1], activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "wrapped_model = KerasModelWrapper(\n",
    "    model=model,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "nn_results = evaluate_model(\n",
    "    wrapped_model, \n",
    "    x_train_np, y_train_np,\n",
    "    x_test_np, y_test_np,\n",
    "    model_name='Keras Sequential Model'\n",
    ")\n",
    "\n",
    "nn_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Summary Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Table - Test Metrics\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Algorithm              |   Accuracy |   Precision |   Recall |   F1-Score |\n",
      "+========================+============+=============+==========+============+\n",
      "| Logistic Regression    |     0.8187 |      0.8199 |   0.8187 |     0.8186 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Random Forest          |     0.8543 |      0.8567 |   0.8543 |     0.854  |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Decision Tree          |     0.8519 |      0.8553 |   0.8519 |     0.8515 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| SVM                    |     0.8571 |      0.8595 |   0.8571 |     0.8569 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Naive Bayes            |     0.7746 |      0.7787 |   0.7746 |     0.7738 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| KNN                    |     0.829  |      0.829  |   0.829  |     0.829  |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| XGBoost                |     0.8567 |      0.859  |   0.8567 |     0.8565 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| LightGBM               |     0.8589 |      0.8621 |   0.8589 |     0.8586 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| CatBoost               |     0.8575 |      0.8601 |   0.8575 |     0.8572 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| SnapBoost              |     0.8555 |      0.8588 |   0.8555 |     0.8552 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| EBM                    |     0.8493 |      0.8524 |   0.8493 |     0.8489 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| NGBoost                |     0.8408 |      0.8479 |   0.8408 |     0.84   |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| AdaBoost               |     0.8412 |      0.8485 |   0.8412 |     0.8404 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Gradient Boosting      |     0.8509 |      0.8525 |   0.8509 |     0.8507 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Hist Gradient Boosting |     0.8567 |      0.8592 |   0.8567 |     0.8565 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Cascaded Random Forest |     0.8531 |      0.8548 |   0.8531 |     0.8529 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| TabNet Classifier      |     0.8567 |      0.8592 |   0.8567 |     0.8565 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Keras Sequential Model |     0.8585 |      0.8622 |   0.8585 |     0.8581 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "Summary Table - Training Metrics\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Algorithm              |   Accuracy |   Precision |   Recall |   F1-Score |\n",
      "+========================+============+=============+==========+============+\n",
      "| Logistic Regression    |     0.8244 |      0.8254 |   0.8244 |     0.8243 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Random Forest          |     0.8754 |      0.8785 |   0.8754 |     0.8751 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Decision Tree          |     0.8754 |      0.8797 |   0.8754 |     0.875  |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| SVM                    |     0.8606 |      0.8628 |   0.8606 |     0.8603 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Naive Bayes            |     0.7796 |      0.7836 |   0.7796 |     0.7787 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| KNN                    |     0.8512 |      0.8514 |   0.8512 |     0.8511 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| XGBoost                |     0.8705 |      0.8732 |   0.8705 |     0.8702 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| LightGBM               |     0.8659 |      0.8692 |   0.8659 |     0.8656 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| CatBoost               |     0.8711 |      0.8744 |   0.8711 |     0.8708 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| SnapBoost              |     0.858  |      0.861  |   0.858  |     0.8576 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| EBM                    |     0.85   |      0.8529 |   0.85   |     0.8497 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| NGBoost                |     0.8453 |      0.8524 |   0.8453 |     0.8444 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| AdaBoost               |     0.8417 |      0.8503 |   0.8417 |     0.8406 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Gradient Boosting      |     0.8518 |      0.8537 |   0.8518 |     0.8515 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Hist Gradient Boosting |     0.8661 |      0.8687 |   0.8661 |     0.8658 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Cascaded Random Forest |     0.8588 |      0.8607 |   0.8588 |     0.8586 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| TabNet Classifier      |     0.863  |      0.8663 |   0.863  |     0.8627 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Keras Sequential Model |     0.8639 |      0.8677 |   0.8639 |     0.8635 |\n",
      "+------------------------+------------+-------------+----------+------------+\n"
     ]
    }
   ],
   "source": [
    "results = [logreg_results, rf_results, dt_results, \n",
    "        svm_results, nb_results, knn_results, \n",
    "        xgb_results, lgbm_results, catb_results, \n",
    "        snb_results, ebm_results, ngb_results, \n",
    "        adb_results, grb_results, hgrb_results, \n",
    "        gcf_results, tabnet_results, nn_results]\n",
    "\n",
    "create_summary_table(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_el",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
