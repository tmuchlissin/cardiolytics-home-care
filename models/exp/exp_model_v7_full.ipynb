{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,roc_auc_score, classification_report, \n",
    "    confusion_matrix, ConfusionMatrixDisplay, roc_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, StackingClassifier, GradientBoostingClassifier, \n",
    "    HistGradientBoostingClassifier, AdaBoostClassifier\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingClassifier \n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from ngboost import NGBClassifier\n",
    "from ngboost.distns import Bernoulli \n",
    "from snapml import BoostingMachineClassifier  \n",
    "\n",
    "from lib.utils import gcForest\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load & Split Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data 48838\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>systolic</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>bmi</th>\n",
       "      <th>map</th>\n",
       "      <th>pulse_pressure</th>\n",
       "      <th>gender</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>21.97</td>\n",
       "      <td>90.00</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>34.93</td>\n",
       "      <td>106.67</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>23.51</td>\n",
       "      <td>90.00</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>28.71</td>\n",
       "      <td>116.67</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>178</td>\n",
       "      <td>95.0</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>29.98</td>\n",
       "      <td>103.33</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height  weight  systolic  diastolic    bmi     map  pulse_pressure  \\\n",
       "0   50     168    62.0       110         80  21.97   90.00              30   \n",
       "1   55     156    85.0       140         90  34.93  106.67              50   \n",
       "2   51     165    64.0       130         70  23.51   90.00              60   \n",
       "3   48     169    82.0       150        100  28.71  116.67              50   \n",
       "4   61     178    95.0       130         90  29.98  103.33              40   \n",
       "\n",
       "   gender  cholesterol  gluc  smoke  alco  active  cardio  \n",
       "0       1            0     0      0     0       1       0  \n",
       "1       0            2     0      0     0       1       1  \n",
       "2       0            2     0      0     0       0       1  \n",
       "3       1            0     0      0     0       1       1  \n",
       "4       1            2     2      0     0       1       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('data/preprocessed_data_full_encoded_new_v4.csv')\n",
    "\n",
    "cols_to_keep = ['age', \n",
    "                'height',\n",
    "                'weight',\n",
    "                'systolic', \n",
    "                'diastolic',\n",
    "                'bmi',\n",
    "                'map',\n",
    "                'pulse_pressure',\n",
    "                'gender',\n",
    "                'cholesterol', \n",
    "                'gluc',\n",
    "                'smoke', \n",
    "                'alco', \n",
    "                'active',\n",
    "                'cardio'\n",
    "                ]\n",
    "\n",
    "df = df[cols_to_keep]\n",
    "\n",
    "print('Sample Data', len(df)) \n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('cardio', axis=1)  \n",
    "y = df['cardio']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {0: 'Healthy', 1: 'Cardio Risk'}\n",
    "target_names = [label_mapping[label] for label in y.unique()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scaling Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['age', 'height', 'weight', 'systolic', 'diastolic', 'bmi', 'map', 'pulse_pressure']\n",
    "ordinal_features = ['cholesterol', 'gluc']\n",
    "binary_features = ['gender', 'smoke', 'alco', 'active']\n",
    "\n",
    "assert all(feature in X.columns for feature in numerical_features + ordinal_features + binary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>systolic</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>bmi</th>\n",
       "      <th>map</th>\n",
       "      <th>pulse_pressure</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>gender</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.395262</td>\n",
       "      <td>0.496159</td>\n",
       "      <td>-0.937176</td>\n",
       "      <td>-1.090057</td>\n",
       "      <td>-0.186194</td>\n",
       "      <td>-1.153100</td>\n",
       "      <td>-0.672977</td>\n",
       "      <td>-1.394707</td>\n",
       "      <td>-0.576010</td>\n",
       "      <td>-0.421194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.339920</td>\n",
       "      <td>-1.095265</td>\n",
       "      <td>0.902556</td>\n",
       "      <td>0.914602</td>\n",
       "      <td>1.083539</td>\n",
       "      <td>1.612954</td>\n",
       "      <td>1.076080</td>\n",
       "      <td>0.484135</td>\n",
       "      <td>2.217416</td>\n",
       "      <td>-0.421194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.248226</td>\n",
       "      <td>0.098303</td>\n",
       "      <td>-0.777199</td>\n",
       "      <td>0.246383</td>\n",
       "      <td>-1.455926</td>\n",
       "      <td>-0.824418</td>\n",
       "      <td>-0.672977</td>\n",
       "      <td>1.423557</td>\n",
       "      <td>2.217416</td>\n",
       "      <td>-0.421194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.689335</td>\n",
       "      <td>0.628778</td>\n",
       "      <td>0.662591</td>\n",
       "      <td>1.582822</td>\n",
       "      <td>2.353272</td>\n",
       "      <td>0.285418</td>\n",
       "      <td>2.125304</td>\n",
       "      <td>0.484135</td>\n",
       "      <td>-0.576010</td>\n",
       "      <td>-0.421194</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.222138</td>\n",
       "      <td>1.822347</td>\n",
       "      <td>1.702440</td>\n",
       "      <td>0.246383</td>\n",
       "      <td>1.083539</td>\n",
       "      <td>0.556475</td>\n",
       "      <td>0.725639</td>\n",
       "      <td>-0.455286</td>\n",
       "      <td>2.217416</td>\n",
       "      <td>2.881940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48833</th>\n",
       "      <td>0.486956</td>\n",
       "      <td>-0.697409</td>\n",
       "      <td>-0.137292</td>\n",
       "      <td>0.246383</td>\n",
       "      <td>1.083539</td>\n",
       "      <td>0.236330</td>\n",
       "      <td>0.725639</td>\n",
       "      <td>-0.455286</td>\n",
       "      <td>0.820703</td>\n",
       "      <td>1.230373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48834</th>\n",
       "      <td>-0.248226</td>\n",
       "      <td>-0.432172</td>\n",
       "      <td>-1.417106</td>\n",
       "      <td>2.919261</td>\n",
       "      <td>1.083539</td>\n",
       "      <td>-1.232070</td>\n",
       "      <td>2.125304</td>\n",
       "      <td>3.302399</td>\n",
       "      <td>-0.576010</td>\n",
       "      <td>-0.421194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48835</th>\n",
       "      <td>0.633993</td>\n",
       "      <td>0.098303</td>\n",
       "      <td>0.502615</td>\n",
       "      <td>1.582822</td>\n",
       "      <td>-0.186194</td>\n",
       "      <td>0.428417</td>\n",
       "      <td>0.725639</td>\n",
       "      <td>2.362978</td>\n",
       "      <td>-0.576010</td>\n",
       "      <td>-0.421194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48836</th>\n",
       "      <td>1.222138</td>\n",
       "      <td>-0.166934</td>\n",
       "      <td>-0.137292</td>\n",
       "      <td>0.580492</td>\n",
       "      <td>-0.186194</td>\n",
       "      <td>-0.058204</td>\n",
       "      <td>0.201027</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>-0.576010</td>\n",
       "      <td>1.230373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>0.486956</td>\n",
       "      <td>0.761397</td>\n",
       "      <td>-0.137292</td>\n",
       "      <td>-0.421837</td>\n",
       "      <td>-0.186194</td>\n",
       "      <td>-0.525616</td>\n",
       "      <td>-0.323585</td>\n",
       "      <td>-0.455286</td>\n",
       "      <td>0.820703</td>\n",
       "      <td>-0.421194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48838 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    height    weight  systolic  diastolic       bmi       map  \\\n",
       "0     -0.395262  0.496159 -0.937176 -1.090057  -0.186194 -1.153100 -0.672977   \n",
       "1      0.339920 -1.095265  0.902556  0.914602   1.083539  1.612954  1.076080   \n",
       "2     -0.248226  0.098303 -0.777199  0.246383  -1.455926 -0.824418 -0.672977   \n",
       "3     -0.689335  0.628778  0.662591  1.582822   2.353272  0.285418  2.125304   \n",
       "4      1.222138  1.822347  1.702440  0.246383   1.083539  0.556475  0.725639   \n",
       "...         ...       ...       ...       ...        ...       ...       ...   \n",
       "48833  0.486956 -0.697409 -0.137292  0.246383   1.083539  0.236330  0.725639   \n",
       "48834 -0.248226 -0.432172 -1.417106  2.919261   1.083539 -1.232070  2.125304   \n",
       "48835  0.633993  0.098303  0.502615  1.582822  -0.186194  0.428417  0.725639   \n",
       "48836  1.222138 -0.166934 -0.137292  0.580492  -0.186194 -0.058204  0.201027   \n",
       "48837  0.486956  0.761397 -0.137292 -0.421837  -0.186194 -0.525616 -0.323585   \n",
       "\n",
       "       pulse_pressure  cholesterol      gluc  gender  smoke  alco  active  \n",
       "0           -1.394707    -0.576010 -0.421194     1.0    0.0   0.0     1.0  \n",
       "1            0.484135     2.217416 -0.421194     0.0    0.0   0.0     1.0  \n",
       "2            1.423557     2.217416 -0.421194     0.0    0.0   0.0     0.0  \n",
       "3            0.484135    -0.576010 -0.421194     1.0    0.0   0.0     1.0  \n",
       "4           -0.455286     2.217416  2.881940     1.0    0.0   0.0     1.0  \n",
       "...               ...          ...       ...     ...    ...   ...     ...  \n",
       "48833       -0.455286     0.820703  1.230373     0.0    0.0   0.0     1.0  \n",
       "48834        3.302399    -0.576010 -0.421194     0.0    0.0   0.0     1.0  \n",
       "48835        2.362978    -0.576010 -0.421194     0.0    0.0   0.0     1.0  \n",
       "48836        0.953846    -0.576010  1.230373     0.0    0.0   0.0     0.0  \n",
       "48837       -0.455286     0.820703 -0.421194     0.0    0.0   0.0     1.0  \n",
       "\n",
       "[48838 rows x 14 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_standard = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_scaler', scaler_standard, numerical_features),\n",
    "         ('ord_scaler', scaler_standard, ordinal_features)\n",
    "    ],\n",
    "    remainder='passthrough'  \n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "X_preprocessed = pipeline.fit_transform(X)\n",
    "\n",
    "X_preprocessed = pd.DataFrame(X_preprocessed, columns=numerical_features + ordinal_features + binary_features)\n",
    "X_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train, Val, Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "    X_preprocessed, y, test_size=0.3, random_state=42, stratify=y\n",
    ")  # Train 80%\n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(\n",
    "    x_temp, y_temp, test_size=(1/3), random_state=42\n",
    ")  # Val 10%, Test 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_np = np.array(x_train)\n",
    "y_train_np = np.array(y_train)\n",
    "x_test_np = np.array(x_test)\n",
    "y_test_np = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Base Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_train, y_train, x_test, y_test, model_name):\n",
    "    \n",
    "    if hasattr(model, 'cascade_forest'):\n",
    "        print(\"Using cascade_forest branch for training and prediction...\")\n",
    "        model.cascade_forest(x_train, y_train)\n",
    "        predict_func = lambda x: np.argmax(np.mean(model.cascade_forest(x), axis=0), axis=1)\n",
    "        predict_proba_func = lambda x: np.mean(model.cascade_forest(x), axis=0)\n",
    "    else:\n",
    "        print(\"Using standard branch (fit/predict/predict_proba)...\")\n",
    "        model.fit(x_train, y_train)\n",
    "        predict_func = lambda x: model.predict(x)\n",
    "        predict_proba_func = lambda x: model.predict_proba(x)\n",
    "\n",
    "    y_pred_test = predict_func(x_test)\n",
    "    y_proba_test = predict_proba_func(x_test)\n",
    "    \n",
    "    if y_proba_test.shape[1] > 1:\n",
    "        y_probs_test = y_proba_test[:, 1]\n",
    "    else:\n",
    "        y_probs_test = y_proba_test[:, 0]\n",
    "    \n",
    "    y_pred_train = predict_func(x_train)\n",
    "    y_proba_train = predict_proba_func(x_train)\n",
    "    if y_proba_train.shape[1] > 1:\n",
    "        y_probs_train = y_proba_train[:, 1]\n",
    "    else:\n",
    "        y_probs_train = y_proba_train[:, 0]\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    test_acc_str = f\"{(test_accuracy * 100):.2f}%\"\n",
    "    test_auc = roc_auc_score(y_test, y_probs_test)\n",
    "    test_auc_str = f\"{test_auc:.4f}\"\n",
    "    test_report_dict = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "    test_precision = test_report_dict['weighted avg']['precision'] \n",
    "    test_recall    = test_report_dict['weighted avg']['recall']   \n",
    "    test_f1        = test_report_dict['weighted avg']['f1-score']\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    train_acc_str = f\"{(train_accuracy * 100):.2f}%\"\n",
    "    train_auc = roc_auc_score(y_train, y_probs_train)\n",
    "    train_auc_str = f\"{train_auc:.4f}\"\n",
    "    train_report_dict = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "    train_precision = train_report_dict['weighted avg']['precision']\n",
    "    train_recall    = train_report_dict['weighted avg']['recall']    \n",
    "    train_f1        = train_report_dict['weighted avg']['f1-score']  \n",
    "\n",
    "    data = [\n",
    "        [\"Test\", test_acc_str, test_auc_str],\n",
    "        [\"Train\", train_acc_str, train_auc_str]\n",
    "    ]\n",
    "\n",
    "    headers = [\"\", \"Accuracy\", \"AUC Score\"]\n",
    "\n",
    "    print(f\"\\n=== {model_name} ===\\n\")\n",
    "    print(tabulate(data, headers=headers, tablefmt=\"grid\"))\n",
    "    \n",
    "    print(\"\\nOverfitting Check :\")\n",
    "    if train_accuracy > test_accuracy + 5 or train_auc > test_auc + 0.05:\n",
    "        print(\"The model might be overfitting.\")\n",
    "    else:\n",
    "        print(\"No significant signs of overfitting.\\n\")\n",
    "    \n",
    "    # # Plot Confusion Matrix and ROC Curve\n",
    "    # fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    # cm = confusion_matrix(y_test, y_pred_test)\n",
    "    # # If a global variable 'label_mapping' exists, use it for display labels\n",
    "    # display_labels = list(label_mapping.values()) if 'label_mapping' in globals() else None\n",
    "    # disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
    "    # disp.plot(ax=axes[0], cmap='viridis', colorbar=False)\n",
    "    # axes[0].set_title(f\"{model_name} - Confusion Matrix\")\n",
    "    \n",
    "    # fpr, tpr, _ = roc_curve(y_test, y_probs_test)\n",
    "    # axes[1].plot(fpr, tpr, label=f\"ROC Curve (AUC = {test_auc:.4f})\", linewidth=2)\n",
    "    # axes[1].plot([0, 1], [0, 1], 'k--', label=\"Random Guess\", linewidth=1)\n",
    "    # axes[1].set_title(f\"{model_name} - ROC Curve\")\n",
    "    # axes[1].legend(loc=\"lower right\")\n",
    "    # axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'train_precision': train_precision,\n",
    "        'train_recall': train_recall,\n",
    "        'train_f1': train_f1,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1\n",
    "    }\n",
    "\n",
    "\n",
    "def create_summary_table(results):\n",
    "    test_summary = pd.DataFrame([{\n",
    "        'Algorithm': r['model_name'],\n",
    "        'Accuracy':  round(r['test_accuracy'], 4),\n",
    "        'Precision': round(r['test_precision'], 4),\n",
    "        'Recall':    round(r['test_recall'], 4),\n",
    "        'F1-Score':  round(r['test_f1'], 4)\n",
    "    } for r in results])\n",
    "    train_summary = pd.DataFrame([{\n",
    "        'Algorithm': r['model_name'],\n",
    "        'Accuracy':  round(r['train_accuracy'], 4),\n",
    "        'Precision': round(r['train_precision'], 4),\n",
    "        'Recall':    round(r['train_recall'], 4),\n",
    "        'F1-Score':  round(r['train_f1'], 4)\n",
    "    } for r in results])\n",
    "    \n",
    "    \n",
    "    print(\"\\nSummary Table - Test Metrics\")\n",
    "    print(tabulate(test_summary, headers='keys', tablefmt='grid', showindex=False))\n",
    "\n",
    "    print(\"Summary Table - Training Metrics\")\n",
    "    print(tabulate(train_summary, headers='keys', tablefmt='grid', showindex=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Logistic Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.95%     |      0.9259 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 85.94%     |      0.923  |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression()\n",
    "logreg_results = evaluate_model(logreg_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Logistic Regression\")\n",
    "logreg_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Random Forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== Random Forest ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 87.59%     |      0.9556 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 99.59%     |      0.9999 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_results = evaluate_model(rf_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Random Forest\")\n",
    "rf_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Decision Tree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== Decision Tree ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 84.60%     |      0.8472 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 99.59%     |      1      |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "The model might be overfitting.\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_results = evaluate_model(dt_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Decision Tree\")\n",
    "dt_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `SVM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 87.63%     |      0.9518 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 88.11%     |      0.9563 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(probability=True)\n",
    "svm_results = evaluate_model(svm_model, x_train_np, y_train_np, x_test_np, y_test_np, \"SVM\")\n",
    "svm_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Naive Bayes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== Naive Bayes ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.11%     |      0.9292 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 84.61%     |      0.927  |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_results = evaluate_model(nb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Naive Bayes\")\n",
    "nb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `KNN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== KNN ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.89%     |      0.9369 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 90.45%     |      0.9745 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_results = evaluate_model(knn_model, x_train_np, y_train_np, x_test_np, y_test_np, \"KNN\")\n",
    "knn_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `XGBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== XGBoost ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 87.29%     |      0.9596 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 92.21%     |      0.9823 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_results = evaluate_model(xgb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"XGBoost\")\n",
    "xgb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Light GBM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== LightGBM ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 87.65%     |      0.9618 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 89.53%     |      0.9717 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm_model = LGBMClassifier(verbose=-1)\n",
    "lgbm_results = evaluate_model(lgbm_model, x_train_np, y_train_np, x_test_np, y_test_np, \"LightGBM\")\n",
    "lgbm_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Cat Boost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== CatBoost ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 87.41%     |      0.9607 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 91.19%     |      0.9775 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "catb_model = CatBoostClassifier(verbose=False)\n",
    "catb_results = evaluate_model(catb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"CatBoost\")\n",
    "catb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `SnapBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== SnapBoost ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 87.26%     |      0.9573 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 88.12%     |      0.9622 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snb_model = BoostingMachineClassifier()\n",
    "snb_results = evaluate_model(snb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"SnapBoost\")\n",
    "snb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Explainable Boosting Machine (EBM)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== EBM ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 86.71%     |      0.9521 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 87.27%     |      0.9539 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ebm_model = ExplainableBoostingClassifier(n_jobs=1)\n",
    "ebm_results = evaluate_model(ebm_model, x_train_np, y_train_np, x_test_np, y_test_np, \"EBM\")\n",
    "ebm_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `NGBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== NGBoost ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 86.00%     |      0.951  |\n",
      "+-------+------------+-------------+\n",
      "| Train | 86.13%     |      0.9505 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngb_model = NGBClassifier(Dist=Bernoulli, verbose=False)\n",
    "ngb_results = evaluate_model(ngb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"NGBoost\")\n",
    "ngb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `AdaBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== AdaBoost ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 85.59%     |      0.929  |\n",
      "+-------+------------+-------------+\n",
      "| Train | 85.77%     |      0.9294 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adb_model = AdaBoostClassifier(random_state=42)\n",
    "adb_results = evaluate_model(adb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"AdaBoost\")\n",
    "adb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `GradientBoosting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== Gradient Boosting ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 87.35%     |      0.9553 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 87.63%     |      0.9578 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grb_model =  GradientBoostingClassifier(random_state=42)\n",
    "grb_results = evaluate_model(grb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Gradient Boosting\")\n",
    "grb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Hist GradientBoosting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== Hist Gradient Boosting ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 87.74%     |      0.9624 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 89.55%     |      0.9716 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hgrb_model =  HistGradientBoostingClassifier(random_state=42)\n",
    "hgrb_results = evaluate_model(hgrb_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Hist Gradient Boosting\")\n",
    "hgrb_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Cascaded Random Forest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cascade_forest branch for training and prediction...\n",
      "Adding/Training Layer, n_layer=1\n",
      "Layer validation accuracy = 0.855805791167008\n",
      "Adding/Training Layer, n_layer=2\n",
      "Layer validation accuracy = 0.8642878034513015\n",
      "Adding/Training Layer, n_layer=3\n",
      "Layer validation accuracy = 0.8657502193623866\n",
      "Adding/Training Layer, n_layer=4\n",
      "Layer validation accuracy = 0.8676513600467973\n",
      "Adding/Training Layer, n_layer=5\n",
      "Layer validation accuracy = 0.8686750511845569\n",
      "Adding/Training Layer, n_layer=6\n",
      "Layer validation accuracy = 0.8689675343667739\n",
      "Adding/Training Layer, n_layer=7\n",
      "Layer validation accuracy = 0.8704299502778591\n",
      "Adding/Training Layer, n_layer=8\n",
      "Layer validation accuracy = 0.870137467095642\n",
      "\n",
      "=== Cascaded Random Forest ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 86.98%     |      0.9557 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 87.61%     |      0.9582 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gcf_model = gcForest(n_cascadeRF=2,n_cascadeRFtree=500) #Default values tolerance =0.0 ,n_cascadeRFtree=101\n",
    "gcf_results = evaluate_model(gcf_model, x_train_np, y_train_np, x_test_np, y_test_np, \"Cascaded Random Forest\")\n",
    "gcf_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TabNet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\n",
      "=== TabNet Classifier ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 87.49%     |      0.9596 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 89.09%     |      0.9687 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = {'n_d': 55, 'n_a': 39, 'n_steps': 9, 'gamma': 1.0350228727394724, 'lambda_sparse': 1.3957603942801675e-05, 'momentum': 0.4587005208996888, 'clip_value': 1.2827518858412652, 'seed': 4478, 'verbose': 0}\n",
    "tabnet_model = TabNetClassifier(**best_params)\n",
    "tabnet_results = evaluate_model(tabnet_model, x_train_np, y_train_np, x_test_np, y_test_np, \"TabNet Classifier\")\n",
    "tabnet_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `NN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasModelWrapper(BaseEstimator):\n",
    "    def __init__(self, model, epochs=100, batch_size=32, validation_split=0.2, callbacks=None):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_split = validation_split\n",
    "        self.callbacks = callbacks\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.model.fit(\n",
    "            x, y,\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            validation_split=self.validation_split,\n",
    "            callbacks=self.callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        proba = self.model.predict(x)\n",
    "        return (proba > 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        proba = self.model.predict(x)\n",
    "        return np.hstack([1 - proba, proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standard branch (fit/predict/predict_proba)...\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step\n",
      "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step\n",
      "\u001b[1m1069/1069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step\n",
      "\n",
      "=== Keras Sequential Model ===\n",
      "\n",
      "+-------+------------+-------------+\n",
      "|       | Accuracy   |   AUC Score |\n",
      "+=======+============+=============+\n",
      "| Test  | 87.45%     |      0.9585 |\n",
      "+-------+------------+-------------+\n",
      "| Train | 87.91%     |      0.9612 |\n",
      "+-------+------------+-------------+\n",
      "\n",
      "Overfitting Check :\n",
      "No significant signs of overfitting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, input_dim=x_train_np.shape[1], activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "wrapped_model = KerasModelWrapper(\n",
    "    model=model,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "nn_results = evaluate_model(\n",
    "    wrapped_model, \n",
    "    x_train_np, y_train_np,\n",
    "    x_test_np, y_test_np,\n",
    "    model_name='Keras Sequential Model'\n",
    ")\n",
    "\n",
    "nn_results;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Summary Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Table - Test Metrics\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Algorithm              |   Accuracy |   Precision |   Recall |   F1-Score |\n",
      "+========================+============+=============+==========+============+\n",
      "| Logistic Regression    |     0.8595 |      0.8623 |   0.8595 |     0.8593 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Random Forest          |     0.8759 |      0.876  |   0.8759 |     0.8759 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Decision Tree          |     0.846  |      0.846  |   0.846  |     0.846  |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| SVM                    |     0.8763 |      0.8787 |   0.8763 |     0.8762 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Naive Bayes            |     0.8511 |      0.8595 |   0.8511 |     0.8503 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| KNN                    |     0.8589 |      0.8591 |   0.8589 |     0.8589 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| XGBoost                |     0.8729 |      0.8734 |   0.8729 |     0.8728 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| LightGBM               |     0.8765 |      0.8774 |   0.8765 |     0.8765 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| CatBoost               |     0.8741 |      0.8751 |   0.8741 |     0.874  |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| SnapBoost              |     0.8726 |      0.8742 |   0.8726 |     0.8725 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| EBM                    |     0.8671 |      0.8699 |   0.8671 |     0.8669 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| NGBoost                |     0.86   |      0.8663 |   0.86   |     0.8594 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| AdaBoost               |     0.8559 |      0.864  |   0.8559 |     0.8551 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Gradient Boosting      |     0.8735 |      0.8758 |   0.8735 |     0.8733 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Hist Gradient Boosting |     0.8774 |      0.8783 |   0.8774 |     0.8773 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Cascaded Random Forest |     0.8698 |      0.8708 |   0.8698 |     0.8697 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| TabNet Classifier      |     0.8774 |      0.8799 |   0.8774 |     0.8772 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Keras Sequential Model |     0.8745 |      0.8749 |   0.8745 |     0.8745 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "Summary Table - Training Metrics\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Algorithm              |   Accuracy |   Precision |   Recall |   F1-Score |\n",
      "+========================+============+=============+==========+============+\n",
      "| Logistic Regression    |     0.8594 |      0.8611 |   0.8594 |     0.8592 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Random Forest          |     0.9959 |      0.9959 |   0.9959 |     0.9959 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Decision Tree          |     0.9959 |      0.996  |   0.9959 |     0.9959 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| SVM                    |     0.8811 |      0.8823 |   0.8811 |     0.881  |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Naive Bayes            |     0.8461 |      0.8525 |   0.8461 |     0.8452 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| KNN                    |     0.9045 |      0.9046 |   0.9045 |     0.9045 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| XGBoost                |     0.9221 |      0.9225 |   0.9221 |     0.922  |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| LightGBM               |     0.8953 |      0.8958 |   0.8953 |     0.8952 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| CatBoost               |     0.9119 |      0.9123 |   0.9119 |     0.9118 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| SnapBoost              |     0.8812 |      0.8818 |   0.8812 |     0.8811 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| EBM                    |     0.8727 |      0.8739 |   0.8727 |     0.8725 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| NGBoost                |     0.8613 |      0.865  |   0.8613 |     0.8609 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| AdaBoost               |     0.8577 |      0.8636 |   0.8577 |     0.8569 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Gradient Boosting      |     0.8763 |      0.8774 |   0.8763 |     0.8762 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Hist Gradient Boosting |     0.8955 |      0.896  |   0.8955 |     0.8954 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Cascaded Random Forest |     0.8761 |      0.8765 |   0.8761 |     0.876  |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| TabNet Classifier      |     0.8836 |      0.8851 |   0.8836 |     0.8834 |\n",
      "+------------------------+------------+-------------+----------+------------+\n",
      "| Keras Sequential Model |     0.8791 |      0.8791 |   0.8791 |     0.8791 |\n",
      "+------------------------+------------+-------------+----------+------------+\n"
     ]
    }
   ],
   "source": [
    "results = [logreg_results, rf_results, dt_results, \n",
    "        svm_results, nb_results, knn_results, \n",
    "        xgb_results, lgbm_results, catb_results, \n",
    "        snb_results, ebm_results, ngb_results, \n",
    "        adb_results, grb_results, hgrb_results, \n",
    "        gcf_results, tabnet_results, nn_results]\n",
    "\n",
    "create_summary_table(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_el",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
